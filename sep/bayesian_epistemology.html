<div id="article-content">

<!-- BEGIN ARTICLE HTML -->


<div id="aueditable"><!--DO NOT MODIFY THIS LINE AND ABOVE-->

<h1>Bayesian Epistemology</h1><div id="pubinfo"><em>First published Thu Jul 12, 2001; substantive revision Wed Mar 26, 2008</em></div>

<div id="preamble">

<p>

&#8216;Bayesian epistemology&#8217; became an epistemological movement
in the 20<sup>th</sup> century, though its two main features can be
traced back to the eponymous Reverend Thomas Bayes (c. 1701&#8211;61). Those
two features are: (1) the introduction of a <em>formal apparatus</em>
for inductive logic; (2) the introduction of a <em>pragmatic
self-defeat test</em> (as illustrated by Dutch Book Arguments) for
<em>epistemic</em> rationality as a way of extending the justification
of the laws of deductive logic to include a justification for the laws
of inductive logic. The formal apparatus itself has two main elements:
the use of the laws of probability as coherence constraints on
rational degrees of belief (or degrees of confidence) and the
introduction of a rule of probabilistic inference, a rule or principle
of <em>conditionalization</em>.
</p>

<p>

Bayesian epistemology did not emerge as a philosophical program
until the first formal axiomatizations of probability theory in the
first half of the 20<sup>th</sup> century. One important
application of Bayesian epistemology has been to the analysis of
scientific practice in <em>Bayesian Confirmation Theory</em>. In
addition, a major branch of statistics, <em>Bayesian
statistics</em>, is based on Bayesian principles. In psychology,
an important branch of learning theory, <em>Bayesian learning
theory</em>, is also based on Bayesian principles. Finally, the
idea of analyzing rational degrees of belief in terms of rational
betting behavior led to the 20<sup>th</sup> century development of a
new kind of decision theory, <em>Bayesian decision theory</em>, which is
now the dominant theoretical model for both the descriptive and
normative analysis of decisions. The combination of its precise
formal apparatus and its novel pragmatic self-defeat test for
justification makes Bayesian epistemology one of the most important
developments in epistemology in the 20<sup>th</sup> century, and one of
the most promising avenues for further progress in epistemology in the
21<sup>st</sup> century. </p>

</div>

<div id="toc">
<!--Entry Contents-->
<ul>
<li><a href="#DedProCohDedProRulInf">1. Deductive and Probabilistic Coherence and Deductive and Probabilistic Rules of Inference</a></li>
<li><a href="#SimPriCon">2. A Simple Principle of Conditionalization</a></li>
<li><a href="#DutBooArg">3. Dutch Book Arguments</a></li>
<li><a href="#BayTheBayConThe">4. Bayes' Theorem and Bayesian Confirmation Theory</a>
   <ul>
   <li><a href="#BayTheCor">Bayes' Theorem and a Corollary</a></li>
   <li><a href="#BayConThe">Bayesian Confirmation Theory</a></li>
   </ul></li>
<li><a href="#BaySocEpi">5. Bayesian Social Epistemology</a></li>
<li><a href="#PotPro">6. Potential Problems</a>
   <ul>
   <li><a href="#ObjProLawStaSynCoh">6.1 Objections to the Probability Laws as Standards of Synchronic Coherence</a></li>
   <li><a href="#ObjSimPriConRulInfOthObjBayConThe">6.2 Objections to The Simple Principle of Conditionalization as a Rule of Inference and Other Objections to Bayesian Confirmation Theory</a></li>
   </ul></li>
<li><a href="#OthPriBayEpi">7. Other Principles of Bayesian Epistemology</a></li>
<li><a href="#Bib">Bibliography</a></li>
<li><a href="#Aca">Academic Tools</a></li>
<li><a href="#Oth">Other Internet Resources</a></li>
<li><a href="#Rel">Related Entries</a></li>
</ul>
<!--Entry Contents-->

<hr>

</div>

<div id="main-text">

<h2><a name="DedProCohDedProRulInf">1. Deductive and Probabilistic Coherence and Deductive and Probabilistic Rules of Inference</a></h2>

<p>

There are two ways that the laws of deductive logic have been thought
to provide rational constraints on belief: (1) Synchronically, the
laws of deductive logic can be used to define the notion of deductive
consistency and inconsistency. Deductive inconsistency so defined
determines one kind of incoherence in belief, which I refer to as
<em>deductive incoherence</em>. (2) Diachronically, the laws of
deductive logic can constrain admissible changes in belief by
providing the <em>deductive rules of inference</em>. For example,
<em>modus ponens</em> is a deductive rule of inference that requires
that one infer <em>Q</em> from premises <em>P</em> and <em>P</em>
 &#8594; <em>Q</em>.</p>

<p>

Bayesians propose additional standards of synchronic coherence &#8212;
standards of <em>probabilistic coherence</em> &#8212; and additional rules
of inference &#8212; <em>probabilistic rules of inference</em> &#8212; in both
cases, to apply not to beliefs, but degrees of belief (degrees of
confidence). For Bayesians, the most important standards of
probabilistic coherence are the laws of probability. For more on the
laws of probability, see the following supplementary article:</p>

<blockquote>
 <a href="https://plato.stanford.edu/entries/epistemology-bayesian/supplement1.html" name="return-1">Supplement on Probability Laws</a>
</blockquote>

<p>

For Bayesians, the most important probabilistic rule of inference is
given by a <em>principle of conditionalization</em>. </p>

<h2><a name="SimPriCon">2. A Simple Principle of Conditionalization</a></h2>

<p>

If unconditional probabilities (e.g. <em>P</em>(<em>S</em>)) are taken
as primitive, the conditional probability of <em>S</em> on <em>T</em>
can be defined as follows:</p>

<blockquote>
<strong>Conditional Probability</strong>:<br>
 <em>P</em>(<em>S</em>/<em>T</em>) =
 <em>P</em>(<em>S</em>&amp;<em>T</em>)/<em>P</em>(<em>T</em>).
</blockquote>

<p>

By itself, the definition of conditional probability is of little
epistemological significance. It acquires epistemological
significance only in conjunction with a further epistemological
assumption:</p>

<blockquote>
<strong>Simple Principle of Conditionalization</strong>:<br> 
 If one begins with initial or <em>prior</em> probabilities
<em>P</em><sub><em>i</em></sub>, and one acquires new evidence which
can be represented as becoming certain of an evidentiary statement
<em>E</em> (assumed to state the totality of one's new evidence
and to have initial probability greater than zero), then rationality
requires that one systematically transform one's initial
probabilities to generate final or <em>posterior</em> probabilities
<em>P</em><sub><em>f</em></sub> by conditionalizing on <em>E</em> &#8212;
that is: Where <em>S</em> is any statement,
<em>P</em><sub><em>f</em></sub>(<em>S</em>) =
 <em>P</em><sub><em>i</em></sub>(<em>S</em>/<em>E</em>).<sup>[<a href="https://plato.stanford.edu/entries/epistemology-bayesian/notes.html#1" name="note-1">1</a>]</sup>
 </blockquote>

<p>

In epistemological terms, this Simple Principle of Conditionalization
requires that the effects of evidence on rational degrees be analyzed
in two stages: The first is non-inferential. It is the change in the
probability of the evidence statement <em>E</em> from
<em>P</em><sub><em>i</em></sub>(<em>E</em>), assumed to be greater
than zero and less than one, to
<em>P</em><sub><em>f</em></sub>(<em>E</em>) = 1. The second is a
probabilistic inference of conditionalizing on <em>E</em> from initial
probabilities (e.g., <em>P</em><sub><em>i</em></sub>(<em>S</em>)) to
final probabilities (e.g., <em>P</em><sub><em>f</em></sub>(<em>S</em>)
= <em>P</em><sub><em>i</em></sub>(<em>S</em>/<em>E</em>)).</p>

<p>

Problems with the Simple Principle (to be discussed below) have led
many Bayesians to qualify the Simple Principle by limiting its
scope. In addition, some Bayesians follow Jeffrey in generalizing the
Simple Principle to apply to cases in which one's new evidence is less
than certain (also discussed below). What unifies Bayesian
epistemology is a conviction that conditionalizing (perhaps of a
generalized sort) is rationally required in some important contexts
&#8212; that is, that some sort of conditionalization principle is an
important principle governing rational changes in degrees of
belief.</p>

<h2><a name="DutBooArg">3. Dutch Book Arguments</a></h2>

<p>

Many arguments have been given for regarding the probability laws as
coherence conditions on degrees of belief and for taking some
principle of conditionalization to be a rule of probabilistic
inference. The most distinctively Bayesian are those referred to as
<em>Dutch Book Arguments</em>. Dutch Book Arguments represent the
possibility of a new kind of justification for epistemological
principles.</p>

<p>

A Dutch Book Argument relies on some descriptive or normative
assumptions to connect degrees of belief with willingness to wager &#8212;
for example, a person with degree of belief <em>p</em> in sentence
<em>S</em> is assumed to be willing to pay up to and including
$<em>p</em> for a unit wager on <em>S</em> (i.e., a wager that pays $1
if <em>S</em> is true) and is willing to sell such a wager for any
price equal to or greater than $<em>p</em> (one is assumed to be equally
willing to buy or sell such a wager when the price is exactly
 $<em>p</em>).<sup>[<a href="https://plato.stanford.edu/entries/epistemology-bayesian/notes.html#2" name="note-2">2</a>]</sup>
 A <em>Dutch Book</em> is a combination of
wagers which, on the basis of deductive logic alone, can be shown to
entail a sure loss. A <em>synchronic Dutch Book</em> is a Dutch Book
combination of wagers that one would accept all at the same time.  A
<em>diachronic Dutch Book</em> is a Dutch Book combination of wagers
that one will be motivated to enter into at different times. </p>

<p>

Ramsey and de Finetti first employed synchronic Dutch Book Arguments
in support of the probability laws as standards of synchronic
coherence for degrees of belief. The first diachronic Dutch Book
Argument in support of a principle of conditionalization was reported
by Teller, who credited David Lewis. The Lewis/Teller argument depends
on a further descriptive or normative assumption about conditional
probabilities due to de Finetti: An agent with conditional probability
<em>P</em>(<em>S</em>/<em>T</em>) = <em>p</em> is assumed to be
willing to pay any price up to and including $<em>p</em> for a unit
wager on <em>S</em> conditional on <em>T</em>. (A unit wager on
<em>S</em> conditional on <em>T</em> is one that is called off, with
the purchase price returned to the purchaser, if <em>T</em> is not
true. If <em>T</em> is true, the wager is not called off and the wager
pays $1 if <em>S</em> is also true.)  On this interpretation of
conditional probabilities, Lewis, as reported by Teller, was able to
show how to construct a diachronic Dutch Book against anyone who, on
learning only that <em>T</em>, would predictably change his/her degree
of belief in <em>S</em> to <em>P</em><sub><em>f</em></sub>(<em>S</em>)
&gt; <em>P</em><sub><em>i</em></sub>(<em>S</em>/<em>T</em>); and how
to construct a diachronic Dutch Book against anyone who, on learning
only that <em>T</em>, would predictably change his/her degree of
belief in <em>S</em> to <em>P</em><sub><em>f</em></sub>(<em>S</em>)
&lt; <em>P</em><sub><em>i</em></sub>(<em>S</em>/T<em>)</em>. For
illustrations of the strategy of the Ramsey/de Finetti and the
Lewis/Teller arguments, see the following supplementary article:</p>

<blockquote>
 <a href="https://plato.stanford.edu/entries/epistemology-bayesian/supplement2.html" name="return-2">Supplement on Dutch Book Arguments</a>
</blockquote>

<p>

There has been much discussion of exactly what it is that Dutch Book
Arguments are supposed to show. On the <em>literal-minded
interpretation</em>, their significance is that they show that those
whose degrees of belief violate the probability laws or those whose
probabilistic inferences predictably violate a principle of
conditionalization are liable to enter into wagers on which they are
sure to lose. There is very little to be said for the literal-minded
interpretation, because there is no basis for claiming that
rationality requires that one be willing to wager in accordance with
the behavioral assumptions described above. An agent could simply
refuse to accept Dutch Book combinations of wagers.</p>

<p>

One of the main motivations for Jeffrey's new approach to the
foundations of decision theory in <em>Logic of Decision</em> was his
dissatisfaction with the identification of subjective probability with
betting ratios.  For example, no matter what one's degree of belief in
the proposition that all human life will be destroyed within the next
ten years, it would be not be rational to offer to buy a bet on its
truth.  Williamson extends de Finetti's Dutch Book Argument for a
finite additivity constraint on rational degrees of belief to produce
an argument for a countable additivity constraint on degrees of
belief, but the argument is better interpreted as a reductio of the
literal-minded interpretation of Dutch Book Arguments than as an
argument for the rationality of a countable additivity constraint.
The rational response to offers to bet on the proposition that all
life will be destroyed within the next ten years or to bet on a single
possible outcome in a countably infinite set of equiprobable possible
outcomes is simply not to.</p>

<p>

A more plausible interpretation of Dutch Book Arguments is that they
are to be understood hypothetically, as symptomatic of what has been
termed <em>pragmatic self-defeat</em>. On this interpretation, Dutch
Book Arguments are a kind of heuristic for determining when
one's degrees of belief have the potential to be
<em>pragmatically self-defeating</em>. The problem is not that one
who violates the Bayesian constraints is likely to enter into a
combination of wagers that constitute a Dutch Book, but that, on any
reasonable way of translating one's degrees of belief into
action, there is a potential for one's degrees of belief to
motivate one to act in ways that make things worse than they might
have been, when, as a matter of logic alone, it can be determined
that alternative actions would have made things better (on one's
own evaluations of better and worse). </p>

<p>

Another way of understanding the problem of susceptibility to a Dutch
Book is due to Ramsey: Someone who is susceptible to a Dutch Book
evaluates identical bets differently based on how they are described.
Putting it this way makes susceptibility to Dutch Books sound
irrational.  But this standard of rationality would make it
irrational not to recognize all the logical consequences of what one
believes.  This is the <em>assumption of logical omniscience</em>
(discussed below).  </p>

<p>

If successful, Dutch Book Arguments would reduce the justification
of the principles of Bayesian epistemology to two elements: (1) an
account of the appropriate relationship between degrees of belief and
choice; and (2) the laws of deductive logic. Because it would seem
that the truth about the appropriate relationship between the degrees
of belief and choice is independent of epistemology, Dutch Book
Arguments hold out the potential of justifying the principles of
Bayesian epistemology in a way that requires no other epistemological
resources than the laws of deductive logic. For this reason, it makes
sense to think of Dutch Book Arguments as indirect, pragmatic
arguments for according the principles of Bayesian epistemology much
the same epistemological status as the laws of deductive logic.
Dutch Book Arguments are a truly distinctive contribution made by
Bayesians to the methodology of epistemology.  </p> 

<p>
 It should also be mentioned that some Bayesians have defended their
principles more directly, with non-pragmatic arguments.  In addition
to reporting Lewis's Dutch Book Argument, Teller offers a
non-pragmatic defense of Conditionalization.  There have been many
proposed non-pragmatic defenses of the probability laws (e.g., van
Fraassen; Shimony).  The most compelling is due to Joyce.  All such
defenses, whether pragmatic or non-pragmatic, produce a puzzle for
Bayesian epistemology: The principles of Bayesian epistemology are
typically proposed as principles of <em>inductive</em> reasoning.  But
if the principles of Bayesian epistemology depend ultimately for their
justification solely on the laws of deductive logic, what reason is
there to think that they have any <em>inductive</em> content?  That is
to say, what reason is there to believe that they do anything more
than extend the laws of deductive logic from beliefs to degrees of
belief?  It should be mentioned, however, that even if Bayesian
epistemology only extended the laws of deductive logic to degrees of
belief, that alone would represent an extremely important advance in
epistemology.  </p>

<h2><a name="BayTheBayConThe">4. Bayes' Theorem and Bayesian Confirmation Theory</a></h2>

<p>

This section reviews some of the most important results in the
Bayesian analysis of scientific practice &#8212; <em>Bayesian Confirmation
Theory</em>. It is assumed that all statements to be evaluated have
prior probability greater than zero and less than one.</p>

<h3><a name="BayTheCor">4.1 Bayes' Theorem and a Corollary</a></h3>

<p>
Bayes' Theorem is a straightforward consequence of the probability
axioms and the definition of conditional probability:</p>

<blockquote>
<strong>Bayes' Theorem</strong>:<br>
 <em>P</em>(<em>S</em>/<em>T</em>) = <em>P</em>(<em>T</em>/<em>S</em>)
 &#215;
<em>P</em>(<em>S</em>)/<em>P</em>(<em>T</em>) [where
<em>P</em>(<em>T</em>) is assumed to be greater than zero]
</blockquote>

<p>
 The epistemological significance of Bayes' Theorem is that it
provides a straightforward corollary to the Simple Principle of
Conditionalization. Where the final probability of a hypothesis
<em>H</em> is generated by conditionalizing on evidence <em>E</em>,
Bayes' Theorem provides a formula for the final probability of
<em>H</em> in terms of the prior or initial <em>likelihood</em> of
<em>H</em> on <em>E</em>
(<em>P</em><sub><em>i</em></sub>(<em>E</em>/<em>H</em>)) and the prior
or initial probabilities of <em>H</em> and <em>E</em>:</p>

<blockquote> <strong>Corollary of the Simple Principle of
Conditionalization</strong>:<br>

<em>P</em><sub><em>f</em></sub>(<em>H</em>) =
<em>P</em><sub><em>i</em></sub>(<em>H</em>/<em>E</em>) =
<em>P</em><sub><em>i</em></sub>(<em>E</em>/<em>H</em>) &#215;
<em>P</em><sub><em>i</em></sub>(<em>H</em>)/<em>P</em><sub><em>i</em></sub>(<em>E</em>).

</blockquote>

<p>
 Due to the influence of Bayesianism, <em>likelihood</em> is now a
technical term of art in confirmation theory.  As used in this
technical sense, likelihoods can be very useful.  Often, when the
conditional probability of <em>H</em> on <em>E</em> is in doubt, the
likelihood of <em>H</em> on <em>E</em> can be computed from the
theoretical assumptions of <em>H</em>.</p>

<h3><a name="BayConThe">4.2 Bayesian Confirmation Theory</a></h3>

<p>

<strong>A. Confirmation and disconfirmation.</strong> In Bayesian
Confirmation Theory, it is said that evidence confirms (or would
confirm) hypothesis <em>H</em> (to at least some degree) just in case
the prior probability of <em>H</em> conditional on <em>E</em> is
greater than the prior unconditional probability of <em>H</em>:
<em>P</em><sub><em>i</em></sub>(<em>H</em>/<em>E</em>) &gt;
<em>P</em><sub><em>i</em></sub>(<em>H</em>). <em>E</em> disconfirms
(or would disconfirm) <em>H</em> if the prior probability of
<em>H</em> conditional on <em>E</em> is less than the prior
unconditional probability of <em>H</em>.</p>

<p>

This is a qualitative conception of confirmation.  There is no general
agreement in the literature on a quantitative measure of degree of
confirmation or degree of evidential support.  Earman (chap. 5) and
Fitelson both provide a good overview of the various proposals.  It
might be thought that <em>the degree to which evidence E supports (or
would support) hypothesis H</em> could be defined as
<em>P</em><sub><em>i</em></sub>(<em>H</em>/<em>E</em>) &#8722;
<em>P</em><sub><em>i</em></sub>(<em>H</em>).  One potential problem
with this proposal is that it has the consequence that no evidence can
provide much evidential support to a hypothesis that is antecedently
very probable, because as the probability of <em>H</em> approaches
one, the difference goes to zero.  Eells and Fitelson have argued that
this apparently counterintuitive consequence can be avoided by
distinguishing the historical question of how much a piece of evidence
<em>E</em> actually contributed to the confirmation of <em>H</em>
(which, of course, would have to be small if H were antecedently
highly probable) from the question of the degree of evidential support
<em>E</em> provides for <em>H</em>, the answer to which, they propose,
is relative to the background information.  So even if <em>H</em> is
very probable at the time that evidence <em>E</em> is acquired, we can
ask how much evidential support <em>E</em> would provide for
<em>H</em> if we had no other evidence supporting <em>H</em>.  Eells
and Fitelson have also provided a useful framework for evaluating the
various proposals in the literature, a framework within which most of
them are found to be wanting. </p>

<p>

<strong>B. Confirmation and disconfirmation by entailment.</strong>
Whenever a hypothesis <em>H</em> logically entails evidence
<em>E</em>, <em>E</em> confirms <em>H</em>. This follows from the fact
that to determine the truth of <em>E</em> is to rule out a possibility
assumed to have non-zero prior probability that is incompatible with
<em>H</em> &#8212; the possibility that ~<em>E</em>.  A corollary is
that, where <em>H</em> entails <em>E</em>, ~<em>E</em> would
disconfirm <em>H</em>, by reducing its probability to zero.  The most
influential model of explanation in science is the
hypothetico-deductive model (e.g., Hempel).  Thus, one of the most
important sources of support for Bayesian Confirmation Theory is that
it can explain the role of hypothetico-deductive explanation in
confirmation.  </p>

<p>

<strong>C. Confirmation of logical equivalents.</strong> If two
hypotheses H1 and H2 are logically equivalent, then evidence
<em>E</em> will confirm both equally. This follows from the fact that
logically equivalent statements always are assigned the same
probability.</p>

<p>

<strong>D. The confirmatory effect of surprising or diverse
evidence.</strong> From the corollary above, it follows that whether
<em>E</em> confirms (or disconfirms) <em>H</em> depends on whether
<em>E</em> is more probable (or less probable) conditional on
<em>H</em> than it is unconditionally &#8212; that is, on whether:</p>

<blockquote>
 (b1) <em>P</em>(<em>E</em>/<em>H</em>)/<em>P</em>(<em>E</em>) &gt; 1.
</blockquote>

<p>

An intuitive way of understanding (b1) is to say that it states that
<em>E</em> would be more expected (or less surprising) if it were
known that <em>H</em> were true. So if <em>E</em> is surprising, but
would not be surprising if we knew <em>H</em> were true, then
<em>E</em> will significantly confirm <em>H</em>. Thus, Bayesians
explain the tendency of surprising evidence to confirm hypotheses on
which the evidence would be expected.</p>

<p>

Similarly, because it is reasonable to think that evidence
<em>E</em><sub>1</sub> makes other evidence of the same kind much more
probable, after <em>E</em><sub>1</sub> has been determined to be true,
other evidence of the same kind <em>E</em><sub>2</sub> will generally
not confirm hypothesis <em>H</em> as much as other diverse evidence
<em>E</em><sub>3</sub>, even if <em>H</em> is equally likely on both
<em>E</em><sub>2</sub> and <em>E</em><sub>3</sub>. The explanation is
that where <em>E</em><sub>1</sub> makes <em>E</em><sub>2</sub> much
more probable than <em>E</em><sub>3</sub>
(<em>P</em><sub><em>i</em></sub>(<em>E</em><sub>2</sub>/<em>E</em><sub>1</sub>)
&gt;&gt;
<em>P</em><sub><em>i</em></sub>(<em>E</em><sub>3</sub>/<em>E</em><sub>1</sub>),
there is less potential for the discovery that <em>E</em><sub>2</sub>
is true to raise the probability of <em>H</em> than there is for the
discovery that <em>E</em><sub>3</sub> is true to do so. </p>

<p>

<strong>E. Relative confirmation and likelihood ratios.</strong> Often
it is important to be able to compare the effect of evidence
<em>E</em> on two competing hypotheses,
<em>H</em><sub><em>j</em></sub> and H<sub><em>k</em></sub>, without
having also to consider its effect on other hypotheses that may not be
so easy to formulate or to compare with
<em>H</em><sub><em>j</em></sub> and <em>H</em><sub><em>k</em></sub>.
From the first corollary above, the ratio of the final probabilities
of <em>H</em><sub><em>j</em></sub> and <em>H</em><sub><em>k</em></sub>
would be given by:</p>

<blockquote>
<strong>Ratio Formula</strong>:<br>
 <em>P</em><sub><em>f</em></sub>(<em>H</em><sub><em>j</em></sub>)/<em>P</em><sub><em>f</em></sub>(<em>H</em><sub><em>k</em></sub>)
=
[<em>P</em><sub><em>i</em></sub>(<em>E</em>/<em>H</em><sub><em>j</em></sub>)
 &#215;
 <em>P</em><sub><em>i</em></sub>(<em>H</em><sub><em>j</em></sub>)]/[<em>P</em><sub><em>i</em></sub>(<em>E</em>/<em>H</em><sub><em>k</em></sub>)
 &#215;
<em>P</em><sub><em>i</em></sub>(<em>H</em><sub><em>k</em></sub>)]
</blockquote>

<p>

If the <em>odds of</em> H<sub>j</sub> <em>relative to</em>
H<sub>k</sub> are defined as ratio of their probabilities, then from
the Ratio Formula it follows that, in a case in which change in
degrees of belief results from conditionalizing on <em>E</em>, the
final odds
(<em>P</em><sub><em>f</em></sub>(<em>H</em><sub><em>j</em></sub>)/<em>P</em><sub><em>f</em></sub>(<em>H</em><sub><em>k</em></sub>))
result from multiplying the initial odds
(<em>P</em><sub><em>i</em></sub>(<em>H</em><sub><em>j</em></sub>)/<em>P</em><sub><em>i</em></sub>(<em>H</em><sub><em>k</em></sub>))
by the <em>likelihood ratio</em>
(<em>P</em><sub><em>i</em></sub>(<em>E</em>/<em>H</em><sub><em>j</em></sub>)/<em>P</em><sub><em>i</em></sub>(<em>E</em>/<em>H</em><sub><em>k</em></sub>)). Thus,
in pairwise comparisons of the odds of hypotheses, the likelihood
ratio is the crucial determinant of the effect of the evidence on the
odds.</p>

<p>

<strong>F. Subjective and Objective Bayesianism.</strong> Are there
constraints on prior probabilities other than the probability laws?
Consider a situation in which you are to draw a ball from an urn
filled with red and black balls.  Suppose you have no other
information about the urn.  What is the prior probability (before
drawing a ball) that, given that a ball is drawn from the urn, that
the drawn ball will be black?  The question divides Bayesians into two
camps:</p>

<p>

(a) <em>Subjective Bayesians</em> emphasize the relative lack of
rational constraints on prior probabilities.  In the urn example, they
would allow that any prior probability between 0 and 1 might be
rational (though some Subjective Bayesians (e.g., Jeffrey) would rule
out the two extreme values, 0 and 1).  The most extreme Subjective
Bayesians (e.g., de Finetti) hold that the only rational constraint on
prior probabilities is probabilistic coherence.  Others (e.g.,
Jeffrey) classify themselves as subjectivists even though they allow
for some relatively small number of additional rational constraints on
prior probabilities.  Since subjectivists can disagree about
particular constraints, what unites them is that their constraints
rule out very little.  For Subjective Bayesians, our actual prior
probability assignments are largely the result of non-rational
factors&#8212;for example, our own unconstrained, free choice or
evolution or socialization.</p>

<p>

(b) <em>Objective Bayesians</em> (e.g., Jaynes and Rosenkrantz)
emphasize the extent to which prior probabilities are rationally
constrained.  In the above example, they would hold that rationality
requires assigning a prior probability of 1/2 to drawing a black ball
from the urn.  They would argue that any other probability would fail
the following test: Since you have no information at all about which
balls are red and which balls are black, you must choose prior
probabilities that are invariant with a change in label (&#8220;red&#8221; or
&#8220;black&#8221;).  But the only prior probability assignment that is invariant
in this way is the assignment of prior probability of 1/2 to each of
the two possibilities (i.e., that the ball drawn is black or that it
is red).</p>

<p>

In the limit, an Objective Bayesian would hold that rational
constraints uniquely determine prior probabilities in every
circumstance.  This would make the prior probabilities <em>logical
probabilities</em> determinable purely <em>a priori</em>.  None of
those who identify themselves as Objective Bayesians holds this
extreme form of the view.  Nor do they all agree on precisely what the
rational constraints on degrees of belief are.  For example,
Williamson does not accept Conditionalization in any form as a
rational constraint on degrees of belief.  What unites all of the
Objective Bayesians is their conviction that in many circumstances,
symmetry considerations uniquely determine the relevant prior
probabilities and that even when they don't uniquely determine the
relevant prior probabilities, they often so constrain the range of
rationally admissible prior probabilities, as to assure convergence on
the relevant posterior probabilities.  Jaynes identifies four general
principles that constrain prior probabilities, group invariance,
maximium entropy, marginalization, and coding theory, but he does not
consider the list exhaustive.  He expects additional principles to be
added in the future.  However, no Objective Bayesian claims that there
are principles that uniquely determine rational prior probabilities in
all cases.</p>

<p>

By introducing symmetry constraints on prior probabilities, the
Objective Bayesians inherit the difficulties of the classical
Principle of Indifference, so-named by Keynes, but usually attributed
to Laplace.  The simple example of the urn illustrates how invariance
considerations can be used to give content to the Principle of
Indifference.  There the objectivist is able to uniquely determine the
prior probabilities from the requirement that the rational prior
probabilities should be invariant under switching the labels used to
classify the balls in the urn.</p>

<p>

However, it is generally agreed by both objectivists and subjectivists
that ignorance alone cannot be the basis for assigning prior
probabilities.  The reason is that in any particular case there must
be some information to pick out which parameters or which
transformations are the ones among which one is to be indifferent.
Without such information, indifference considerations lead to paradox.
Objective Bayesians have been quite creative in finding ways to
resolve many of the paradoxes (e.g., Jeffreys' solution to Bertrand's
Pardox, Jaynes's solution to Buffon's Needle Paradox, or Mikkelson's
solution to van Mises' Paradox).  But there are always more paradoxes.
Charles, H&#246;cker, Lacker, Le Diberder, and T'Jampens (Other
Internet Resources) provide an actual example from physics where
maximum entropy yields conflicting results depending on
parameterization and where a frequentist approach seems to be superior
to any Objective Bayesian approach that employs any form of
Conditionalization.</p>

<p>

<strong>G. The typical differential effect of positive evidence and
negative evidence.</strong> Hempel first pointed out that we typically
expect the hypothesis that all ravens are black to be confirmed to
some degree by the observation of a black raven, but not by the
observation of a non-black, non-raven. Let <em>H</em> be the
hypothesis that all ravens are black. Let <em>E</em><sub>1</sub>
describe the observation of a non-black, non-raven. Let
<em>E</em><sub>2</sub> describe the observation of a black
raven. Bayesian Confirmation Theory actually holds that both
<em>E</em><sub>1</sub> and <em>E</em><sub>2</sub> may provide some
confirmation for <em>H</em>. Recall that <em>E</em><sub>1</sub>
supports <em>H</em> just in case
<em>P</em><sub><em>i</em></sub>(<em>E</em><sub>1</sub>/<em>H</em>)/<em>P</em><sub><em>i</em></sub>(<em>E</em><sub>1</sub>)
&gt; 1. It is plausible to think that this ratio is ever so slightly
greater than one. On the other hand, <em>E</em><sub>2</sub> would seem to
provide much greater confirmation to <em>H</em>, because, in this example, it
would be expected that
<em>P</em><sub><em>i</em></sub>(<em>E</em><sub>2</sub>/<em>H</em>)/<em>P</em><sub><em>i</em></sub>(<em>E</em><sub>2</sub>)
&gt;&gt;
<em>P</em><sub><em>i</em></sub>(<em>E</em><sub>1</sub>/<em>H</em>)/<em>P</em><sub><em>i</em></sub>(<em>E</em><sub>1</sub>). </p>

<p>

These are only a sample of the results that have provided support
for Bayesian Confirmation Theory as a theory of rational inference for
science. For further examples, see Howson and Urbach. It
should also be mentioned that an important branch of statistics,
<em>Bayesian statistics</em> is based on the principles of Bayesian
epistemology. </p>

<h2><a name="BaySocEpi">5. Bayesian Social Epistemology</a></h2>

<p>

One of the important developments in Bayesian epistemology has been
the exploration of the social dimension to inquiry.  The obvious
example is scientific inquiry, because it is the community of
scientists, rather than any individual scientist, who determine what
is or is not accepted in the discipline.  In addition, scientists
typically work in research groups and even those who work alone rely
on the reports of other scientists to be able to design and carry out
their own work.  Other important examples of the social dimension to
knowledge include the use of juries to make factual determinations in
the legal system and the decentralization of knowledge over the
Internet.</p>

<p>

There are two ways that Bayesian epistemology can be applied to social
inquiry:</p>

<p>

(1) Bayesian epistemology of testimony (understood generally, to
include not only personal testimony but all media sources of
information).  Goldman has developed a Bayesian epistemology of
testimony and applied it to social entities such as science and the
legal system.  In any such approach, a crucial issue is how to
evaluate the reliability of the reports one receives.  Goldman's
approach is to focus on institutional design to motivate the
production of reliable reports.  Bovens and Hartmann instead try to
model how, when there are reports from multiple sources, a Bayesian
agent can use probabilistic reasoning to judge the reliability of the
reports, and thus, how much credence to place in them.  The idea that
in evaluating the probability of a report we are implicitly evaluating
the reliability of the reporter is developed by Barnes as a potential
explanation of the prediction/accommodation asymmetry, discussed in
the next section.</p>

<p>

(2) Aggregate Bayesianism.  If scientific knowledge or jury
deliberations produce a group product, it is natural to consider
whether the group's knowledge can be represented in aggregate form.
In Bayesian terms, the question is whether the individuals'
probabililty assignments can be usefully aggregated into a single
probability assignment that reflects the group's knowledge.  Although
Seidenfeld, Kadane, and Schervish have shown that there is generally
no way to define an aggregate Bayesian expected utility maximizer to
represent the Pareto preferences of a group of two or more individual
Bayesian expected utility maximizers, there is no impossibility result
precluding the aggregation of individual probabililty assignments into
a group probability assignment.  However, there is no generally agreed
upon rule for doing so.  If a group of Bayesian individuals all had
begun from the same initial probabilities, then simply sharing their
evidence would lead them all to the same final probabilities.  It may
seem unfortunate that unanimity in science and other social endeavors
cannot be achieved so easily, but Kitcher has argued that this is a
mistake, because cognitive diversity plays an important role in
scientific progress.</p>

<p>

The fruitfulness of Bayesian social epistemology may ultimately
depend on whether or not the idealizations of Bayesian theory are too
unrealistic.  For example, if one of the important effects of jury
deliberations is that they tend to provide a way for the group to
correct for the irrationality of individual members, then no model of
jurors as ideal Bayesians is likely to be able to explain that feature
of the jury system.</p>

<h2><a name="PotPro">6. Potential Problems</a></h2>

<p>

This section reviews some of the most important potential problems
for Bayesian Confirmation Theory and for Bayesian epistemology
generally. No attempt is made to evaluate their seriousness here,
though there is no generally agreed upon Bayesian solution to any of
them.</p>

<h3><a name="ObjProLawStaSynCoh">6.1 Objections to the Probability Laws as Standards of Synchronic Coherence</a></h3>

<p>

<strong>A. The assumption of logical omniscience.</strong> The
assumption that degrees of belief satisfy the probability laws implies
omniscience about deductive logic, because the probability laws
require that all deductive logical truths have probability one, all
deductive inconsistencies have probability zero, and the probability
of any conjunction of sentences be no greater than <em>any</em> of its
deductive consequences. This seems to be an unrealistic standard for
human beings. Hacking and Garber have made proposals to relax the
assumption of logical omniscience. Because relaxing that assumption
would block the derivation of almost all the important results in
Bayesian epistemology, most Bayesians maintain the assumption of
logical omniscience and treat it as an ideal to which human beings can
only more or less approximate.</p>

<p>

<strong>B. The special epistemological status of the laws of
classical logic.</strong> Even if the assumption of logical
omniscience is not too much of an idealization to provide a useful
model for human reasoning, it has another potentially troubling
consequence.  It commits Bayesian epistemology to some sort of a
priori/a posteriori distinction, because there could be no Bayesian
account of how empirical evidence might make it rational to adopt a
theory with a non-classical logic.  In this respect, Bayesian
epistemology carries over the presumption from traditional
epistemology that the laws of logic are immune to revision on the
basis of empirical evidence.</p>

<p>

It is open to the Bayesian to try to downplay the significance of
this consequence, by articulating an a priori/a posteriori distinction
that aims to be pragmatic rather than metaphysical (e.g., Carnap's
analytic/synthetic distinction).  However, any such account must
address Quine's well-known holistic challenge to the
analytic-synthetic distinction.</p>

<h3><a name="ObjSimPriConRulInfOthObjBayConThe">6.2 Objections to The Simple Principle of Conditionalization as a Rule of Inference and Other Objections to Bayesian Confirmation Theory</a></h3>

<p>

<strong>A. The problem of uncertain evidence.</strong> The Simple
Principle of Conditionalization requires that the acquisition of
evidence be representable as changing one's degree of belief in a
statement <em>E</em> to one &#8212; that is, to certainty. But many
philosophers would object to assigning probability of one to any
contingent statement, even an evidential statement, because, for
example, it is well-known that scientists sometimes give up previously
accepted evidence. Jeffrey has proposed a generalization of the
Principle of Conditionalization that yields that principle as a
special case. Jeffrey's idea is that what is crucial about
observation is not that it yields certainty, but that it generates a
non-inferential change in the probability of an evidential statement
<em>E</em> and its negation ~<em>E</em> (assumed to be the locus of
all the non-inferential changes in probability) from initial
probabilities between zero and one to
<em>P</em><sub><em>f</em></sub>(<em>E</em>) and
<em>P</em><sub><em>f</em></sub>(~<em>E</em>) = [1 &#8722;
<em>P</em><sub><em>f</em></sub>(<em>E</em>)].  Then on
Jeffrey's account, after the observation, the rational degree of
belief to place in an hypothesis <em>H</em> would be given by the
following principle:</p>

<blockquote>
<strong>Principle of Jeffrey Conditionalization</strong>:<br>
  <em>P</em><sub><em>f</em></sub>(<em>H</em>) =
 <em>P</em><sub><em>i</em></sub>(<em>H</em>/<em>E</em>)
 &#215;
 <em>P</em><sub><em>f</em></sub>(<em>E</em>) +
 <em>P</em><sub><em>i</em></sub>(<em>H</em>/~<em>E</em>)
 &#215;
<em>P</em><sub><em>f</em></sub>(~<em>E</em>)
 [where <em>E</em> and <em>H</em> are both assumed to have prior
probabilities between zero and one]
</blockquote>

<p>

Counting in favor of Jeffrey's Principle is its theoretical
elegance. Counting against it is the practical problem that it
requires that one be able to completely specify the direct
non-inferential effects of an observation, something it is doubtful
that anyone has ever done. Skyrms has given it a Dutch Book defense.
</p>

<p>

<strong>B. The problem of old evidence.</strong> On a Bayesian
account, the effect of evidence <em>E</em> in confirming (or
disconfirming) a hypothesis is solely a function of the increase in
probability that accrues to <em>E</em> when it is first determined to
be true. This raises the following puzzle for Bayesian Confirmation
Theory discussed extensively by Glymour: Suppose that <em>E</em> is an
evidentiary statement that has been known for some time &#8212; that
is, that it is <em>old evidence</em>; and suppose that <em>H</em> is a
scientific theory that has been under consideration for some time. One
day it is discovered that <em>H</em> implies <em>E</em>. In scientific
practice, the discovery that <em>H</em> implied <em>E</em> would
typically be taken to provide some degree of confirmatory support for
<em>H</em>. But Bayesian Confirmation Theory seems unable to explain
how a previously known evidentiary statement <em>E</em> could provide
any new support for H. For conditionalization to come into play, there
must be a change in the probability of the evidence statement
<em>E</em>. Where <em>E</em> is old evidence, there is no change in
its probability. Some Bayesians who have tried to solve this problem
(e.g., Garber) have typically tried to weaken the logical omniscience
assumption to allow for the possibility of discovering logical
relations (e.g., that <em>H</em> and suitable auxiliary assumptions
imply <em>E</em>). As mentioned above, relaxing the logical
omniscience assumption threatens to block the derivation of almost all
of the important results in Bayesian epistemology.  Other Bayesians
(e.g., Lange) employ the Bayesian formalism as a tool in the
<em>rational reconstruction</em> of the evidentiary support for a
scientific hypothesis, where it is irrelevant to the rational
reconstruction whether the evidence was discovered before or after the
theory was initially formulated.  Joyce and Christensen agree that
discovering new logical relations between previously accepted evidence
and a theory cannot raise the probability of the theory.  However,
they suggest that using
<em>P</em><sub><em>i</em></sub>(<em>H</em>/<em>E</em>) &#8722;
<em>P</em><sub><em>i</em></sub>(<em>H</em>/<em>-E</em>) as a measure
of support can at least explain how evidence that has probability one
could still support a theory.  Eells and Fitelson have criticized this
proposal and argued that the problem is better addressed by
distinguishing two measures, the historical measure of the degree to
which a piece of evidence <em>E</em> actually confirmed an hypothesis
<em>H</em> and the ahistorical measure of how much a piece of evidence
<em>E</em> would support an hypothesis <em>H</em>, on given background
information <em>B</em>.  The second measure enables us to ask the
ahistorical question of how much <em>E</em> would support <em>H</em>
if we had no other evidence supporting <em>H</em>. </p>

<p>

<strong>C. The problem of rigid conditional probabilities.</strong>
When one conditionalizes, one applies the initial conditional
probabilities to determine final unconditional probabilities.
Throughout, the conditional probabilities themselves do not change;
they remain rigid. Examples of the Problem of Old Evidence are but
one of a variety of cases in which it seems that it can be rational
to change one's initial conditional probabilities. Thus, many
Bayesians reject the Simple Principle of Conditionalization in favor
of a qualified principle, limited to situations in which one does not
change one's initial conditional probabilities. There is no
generally accepted account of when it is rational to maintain rigid
initial conditional probabilities and when it is not.</p>

<p>

<strong>D. The problem of prediction vs. accommodation.</strong>
Related to the problem of Old Evidence is the following potential
problem: Consider two different scenarios. In the first, theory
<em>H</em> was developed in part to <em>accommodate</em> (i.e., to
imply) some previously known evidence E. In the second, theory
<em>H</em> was developed at a time when <em>E</em> was not known. It
was because <em>E</em> was derived as a <em>prediction</em> from
<em>H</em> that a test was performed and <em>E</em> was found to be
true. It seems that E's being true would provide a greater degree of
confirmation for <em>H</em> if the truth of <em>E</em> had been
<em>predicted</em> by <em>H</em> than if <em>H</em> had been developed
to <em>accommodate</em> the truth of <em>E</em>. There is no general
agreement among Bayesians about how to resolve this problem. Some
(e.g., Horwich) argue that Bayesianism implies that there is no
important difference between prediction and accommodation, and try to
defend that implication. Others (e.g., Maher) argue that there is a
way to understand Bayesianism so as to explain why there is an
important difference between prediction and accommodation. </p>

<p>

<strong>E. The problem of new theories.</strong> Suppose that there is
one theory <em>H</em><sub>1</sub> that is generally regarded as highly
confirmed by the available evidence <em>E</em>. It is possible that
simply the introduction of an alternative theory
<em>H</em><sub>2</sub> can lead to an erosion of
<em>H</em><sub>1</sub>'s support. It is plausible to think that
Copernicus' introduction of the heliocentric hypothesis had this
effect on the previously unchallenged Ptolemaic earth-centered
astronomy. This sort of change cannot be explained by
conditionalization. It is for this reason that many Bayesians prefer
to focus on probability ratios of hypotheses (see the Ratio Formula
above), rather than their absolute probability; but it is clear that
the introduction of a new theory could also alter the probability
ratio of two hypotheses &#8212; for example, if it implied one of them
as a special case.</p>

<p>

<strong>F. The problem of the priors.</strong> Are there constraints
on prior probabilities other than the probability laws?  This is the
issue that divides the Subjective from the Objective Bayesians, as
discussed above.  Consider Goodman's &#8220;new riddle of
induction&#8221;: In the past all observed emeralds have been
green. Do those observations provide any more support for the
generalization that all emeralds are green than they do for the
generalization that all emeralds are grue (green if observed before
now; blue if observed later); or do they provide any more support for
the prediction that the next emerald observed will be green than for
the prediction that the next emerald observed will be grue (i.e.,
blue)?  Almost everyone agrees that it would be irrational to have
prior probabilities that were indifferent between green and grue, and
thus made predictions of greenness no more probable than predictions of
grueness.  But there is no generally agreed upon explanation of this
constraint.</p>

<p>

The problem of the priors identifies an important issue between the
Subjective and Objective Bayesians.  If the constraints on rational
inference are so weak as to permit any or almost any probabilistically
coherent prior probabilities, then there would be nothing to make
inferences in the sciences any more rational than inferences in
astrology or phrenology or in the conspiracy reasoning of a paranoid
schizophrenic, because all of them can be reconstructed as inferences
from probabilistically coherent prior probabilities.  Some Subjective
Bayesians believe that their position is not objectionably subjective,
because of results (e.g., Doob or Gaifman and Snir) proving that even
subjects beginning with very different prior probabilities will tend
to converge in their final probabilities, given a suitably long series
of shared observations. These convergence results are not completely
reassuring, however, because they only apply to agents who already
have significant agreement in their priors and they do not assure
convergence in any reasonable amount of time. Also, they typically
only guarantee convergence on the probability of predictions, not on
the probability of theoretical hypotheses. For example, Carnap favored
prior probabilities that would never raise above zero the probability
of a generalization over a potentially infinite number of instances
(e.g., that all crows are black), no matter how many observations of
positive instances (e.g., black crows) one might make without finding
any negative instances (i.e., non-black crows). In addition, the
convergence results depend on the assumption that the only changes in
probabilities that occur are those that are the non-inferential
results of observation on evidential statements and those that result
from conditionalization on such evidential statements.  But almost all
subjectivists allow that it can sometimes be rational to change one's
prior probability assignments.</p>

<p>

Because there is no generally agreed upon solution to the Problem of
the Priors, it is an open question whether Bayesian Confirmation
Theory has inductive content, or whether it merely translates the
framework for rational belief provided by deductive logic into a
corresponding framework for rational degrees of belief.</p>

<h2><a name="OthPriBayEpi">7. Other Principles of Bayesian Epistemology</a></h2>

<p>

Other principles of Bayesian epistemology have been proposed, but
none has garnered anywhere near a majority of support among
Bayesians.  The most important proposals are merely mentioned
here. It is beyond the scope of this entry to discuss them in any
detail.</p>

<p>

<strong>A. Other principles of synchronic coherence.</strong> Are the
probability laws the only standards of synchronic coherence for
degrees of belief?  Van Fraassen has proposed an additional principle
(Reflection or Special Reflection), which he now regards as a special
case of an even more general principle (General
 Reflection).<sup>[<a href="https://plato.stanford.edu/entries/epistemology-bayesian/notes.html#3" name="note-3">3</a>]</sup> </p>

<p>

<strong>B. Other probabilistic rules of inference.</strong> There seem
to be at least two different concepts of probability: the probability
that is involved in degrees of belief (epistemic or subjective
probability) and the probability that is involved in random events,
such as the tossing of a coin (chance). De Finetti thought this was a
mistake and that there was only one kind of probability, subjective
probability. For Bayesians who believe in both kinds of probability,
an important question is: What is (or should be) the relation between
them?  The answer can be found in the various proposals for principles
of direct inference in the literature.  Typically, principles of
direct inference are proposed as principles for inferring subjective
or epistemic probabilities from beliefs about objective chance (e.g.,
Pollock).  Lewis reverses the direction of inference, and proposes to
infer beliefs about objective chance from subjective or epistemic
probabilities, via his (Reformulated) Principal
 Principle.<sup>[<a href="https://plato.stanford.edu/entries/epistemology-bayesian/notes.html#4" name="note-4">4</a>]</sup>
 Strevens argues that it is Lewis's Principal Principle that gives
Bayesianism its inductive content.</p>

<p>

<strong>C. Principles of rational acceptance.</strong> What is the
relation between beliefs and degrees of belief?  Jeffrey proposes to
give up the notion of belief (at least for empirical statements) and
make do with only degrees of belief.  Other authors (e.g., Levi,
Maher, Kaplan) propose principles of rational acceptance as part of
accounts of when it is rational to accept a statement as true, not
merely to regard it as probable.</p>

</div>

<div id="bibliography">

<h2><a name="Bib">Bibliography</a></h2>

<ul class="hanging">

<li>Barnes, Eric Christian, 2005, &#8220;Predictivism for
Pluralists&#8221;, <em>British Journal for the Philosophy of
Science</em> 56: 421&#8211;450.</li>

<li>Bayes, Thomas, 1764, &#8220;An Essay Towards Solving a Problem in the Doctrine
of Chances&#8221;, <em>Philosophical Transactions of the Royal Society of
London</em>, 53: 37&#8211;418, reprinted in E.S. Pearson and M.G.
Kendall, eds., Studies in the History of Statistics and probability
(London: Charles Griffin, 1970).</li>

<li>Bovens, Luc, and Stephan Hartmann, 2003, <em>Bayesian Epistemology</em>,
Oxford: Clarendon Press.</li>

<li>Carnap, Rudolf, 1950, <em>Logical Foundations of Probability</em>,
Chicago: University of Chicago Press.</li>

<li>&#8211;&#8211;&#8211;, 1952, <em>The Continuum of Inductive Methods</em>,
Chicago: University of Chicago Press.</li>

<li>&#8211;&#8211;&#8211;, 1956, &#8220;Meaning Postulates&#8221;,
in <em>Meaning and Necessity</em>, Chicago: Phoenix Books,
222&#8211;229.</li>

<li>Christensen, David, 2004, <em>Putting Logic in its Place: Formal
Constraints on Rational Belief</em>, Oxford: Clarendon Press.</li>

<li>&#8211;&#8211;&#8211;, 1999, &#8220;Measuring
Confirmation&#8221;, <em>Journal of Philosophy</em>, 96: 437&#8211;461.</li>

<li>de Finetti, Bruno, 1937, &#8220;La Prevision: ses lois logiques,
se sources subjectives&#8221;, <em>Annales de l'Institut Henri
Poincare</em>, 7: 1&#8211;68; tTranslated into English and reprinted in
Kyburg and Smokler, <em>Studies in Subjective Probability</em>,
Huntington, NY: Krieger, 1980.</li>

<li>Doob, J.L., 1971, &#8220;What is a
Martingale?&#8221;, <em>American Mathematical Monthly</em>, 78:
451&#8211;462.</li>

<li>Earman, John, 1991, <em>Bayes or Bust? A Critical Examination of
Bayesian Confirmation Theory</em>, Cambridge, MA: MIT Press.</li>

<li>Eells, Ellery, and Branden Fitelson, 2000, &#8220;Measuring
Confirmation and Evidence&#8221;, <em>Journal of Philosophy</em>, 97:
663&#8211;672.</li>

<li>&#8211;&#8211;&#8211;, 2002, &#8220;Symmetries and
Asymmetries in Evidential Support&#8221;, <em>Philosophical
Studies</em>, 107: 129&#8211;142.</li>

<li>Fitelson, Branden, 1999, &#8220;The Plurality of Bayesian Measures
of Confirmation and the Problem of Measure
Sensitivity&#8221;, <em>Philosophy of Science</em> (Proceedings
Supplement), 66: S362&#8211;378.</li>

<li>&#8211;&#8211;&#8211;, 2003, &#8220;Review of James Joyce, <em>The
Foundations of Causal Decision Theory</em>&#8221;, <em>Mind</em>, 112:
545&#8211;551.</li>

<li>Gaifman, H., and Snir, M., 1982, &#8220;Probabilities over Rich
Languages&#8221;,
<em>Journal of Symbolic Logic</em>, 47: 495&#8211;548.</li>

<li>Garber, Daniel, 1983, &#8220;Old Evidence and Logical Omniscience
in Bayesian Confirmation Theory&#8221;, in J. Earman, ed., <em>Testing
Scientific Theories</em> (Midwest Studies in the Philosophy of
Science, Vol. X), Minneapolis: University of Minnesota Press,
99&#8211;131.</li>

<li>Goldman, Alvin I., 1999, <em>Knowledge in a Social World</em>,
Oxford: Clarendon Press.</li>

<li>Goodman, Nelson, 1983, <em>Fact, Fiction, and Forecast</em>, Cambridge:
Harvard University Press.</li>

<li>Glymour, Clark, 1980, <em>Theory and Evidence</em>, Princeton: Princeton
University Press.</li>

<li>Hacking, Ian, 1967, &#8220;Slightly More Realistic Personal Probability&#8221;,
<em>Philosophy of Science</em>, 34: 311&#8211;325.</li>

<li>Hempel, Carl G., 1965, <em>Aspects of Scientific Explanation</em>, New
York: Free Press.</li>

<li>Horwich, Paul, 1982, <em>Probability and Evidence</em>, Cambridge:
Cambridge University Press.</li>

<li>Howson, Colin, and Peter Urbach, 1993, <em>Scientific Reasoning: The
Bayesian Approach</em>, 2nd ed., Chicago: Open Court.</li>

<li>Jaynes, E.T., 1968, &#8220;Prior
Probabilities&#8221;, <em>Institute of Electrical and Electronic
Engineers Transactions on Systems Science and Cybernetics</em>, SSC-4:
227&#8211;241.</li>

<li>&#8211;&#8211;&#8211;, 2003, <em>Probability Theory: The Logic of
Science</em>, G. Larry Bretthorst (ed.), Cambridge: Cambridge
University Press.</li>

<li>Jeffrey, Richard, 1983, <em>The Logic of Decision</em>, 2nd ed.,
Chicago: University of Chicago Press.</li>

<li>&#8211;&#8211;&#8211;, 1992, <em>Probability and the Art of Judgment</em>,
Cambridge: Cambridge University Press.</li>

<li>Jeffreys, Harold, 1948 [1961], <em>Theory of Probability</em>, 3d
ed., Oxford: Clarendon Press.</li>

<li>Joyce, James M., 1998, &#8220;A Nonpragmatic Vindication of
Probabilism&#8221;,
<em>Philosophy of Science</em>, 65: 575&#8211;603.</li>

<li>&#8211;&#8211;&#8211;, 1999, <em>The Foundations of Causal
Decision Theory</em>, Cambridge: Cambridge University Press.</li>

<li>Kaplan, Mark, 1996, <em>Decision Theory as Philosophy</em>,
Cambridge: Cambridge University Press.</li>

<li>Keynes, John Maynard, 1921, <em>A Treatise on Probability</em>,
London: Macmillan.</li>

<li>Kitcher, Philip, 1990, &#8220;The Division of Cognitive
Labor&#8221;, <em>Journal of Philosophy</em>, 87: 5&#8211;22.</li>

<li>Lange, Marc, 1999, &#8220;Calibration and the Epistemological Role of Bayesian
Conditionalization&#8221;, <em>Journal of Philosophy</em>, 96:
294&#8211;324.</li>

<li>Laplace, P. S. Marquis de, 1820 [1886], <em>Th&#233;orie
Analytique des Probabilitis</em>, 3d ed., Paris:
Gauthier-Villars.</li>

<li>Levi, Isaac, 1980, <em>The Enterprise of Knowledge</em>, Cambridge,
Mass.: MIT Press.</li>

<li>&#8211;&#8211;&#8211;, 1991, <em>The Fixation Of Belief And Its
Undoing</em>, Cambridge: Cambridge University Press.</li>

<li>Lewis, David, 1980, &#8220;A Subjectivist's Guide to Objective Chance&#8221;, in
Richard C. Jeffrey (ed.), <em>Studies in Inductive Logic and
Probability</em> (Vol. 2), Berkeley: University of California Press,  263&#8211;293.</li>

<li>Maher, Patrick, 1988, &#8220;Prediction, Accommodation, and the
Logic of Discovery&#8221;, <em>PSA</em>, 1: 273&#8211;285.</li>

<li>Maher, Patrick, 1993, <em>Betting on Theories</em>, Cambridge:
Cambridge University Press.</li>

<li>Mikkelson, Jeffrey M., 2004, &#8220;Dissolving the Wine/Water Paradox&#8221;,
<em>British Journal for the Philosophy of Science</em>, 55:
137&#8211;145.</li>

<li>Pollock, John L., 1990, <em>Nomic Probability and the Foundations
of Induction</em>, Oxford: Oxford University Press.</li>

<li>Popper, Karl, 1968, <em>The Logic of Scientific Discovery</em>,
3<sup>rd</sup> ed., London: Hutchinson.</li>

<li>Quine, W.V.O., 1966, &#8220;Carnap on Logical Truth&#8221;,
in <em>The Ways of Paradox</em>, New York: Random House: 100&#8211;125.</li>

<li>Ramsey, Frank P., 1926, &#8220;Truth and Probability,&#8221; in
Richard B.  Braithwaite (ed.), <em>Foundations of Mathematics and
Other Logical Essay</em>, London: Routledge and Kegan Paul, 1931,
pp. 156&#8211;198.</li>

<li>R&#233;yni, A., 1955, &#8220;On a New Axiomatic Theory of
Probability&#8221;, <em>Acta Mathematica Academiae Scientiarium
Hungaricae</em>, 6: 285&#8211;385.</li>

<li>Rosenkrantz, R.D., 1981, <em>Foundations and Applications of Inductive
Probability</em>, Atascadero, CA: Ridgeview Publishing.</li>

<li>Savage, Leonard, 1972, <em>The Foundations of Statistics</em>, 2nd ed.,
New York: Dover.</li>

<li>Seidenfeld, Teddy, Joseph B. Kadane, and Mark J. Schervish, 1989,
&#8220;On the Shared Preferences of Two Bayesian Decision
Makers&#8221;, <em>Journal of Philosophy</em>, 86: 225&#8211;244.</li>

<li>Shimony, Abner, 1988, &#8220;An Adamite Derivation of the Calculus
of Probability&#8221;, in J.H. Fetzer (ed.), <em>Probability and
Causalty</em>, Dordrecht: Reidel.</li>

<li>Skyrms, Brian, 1984, <em>Pragmatics and Empiricism</em>, New
Haven: Yale University Press.</li>

<li>&#8211;&#8211;&#8211;, 1990, <em>The Dynamics of Rational
Deliberation</em>, Cambridge, Mass.: Harvard University Press.</li>

<li>Sober, Elliott, 2002, &#8220;Bayesianism&#8212;Its Scope and
Limits&#8221;, in Richard Swinburne (ed.), <em>Bayes's Theorem</em>,
Oxford: Oxford University Press, 21&#8211;38.</li>

<li>Strevens, Michael, 2004, &#8220;Bayesian Confirmation Theory:
Inductive Logic, or Mere Inductive
Framework?&#8221;, <em>Synthese</em>, 141: 365&#8211;379.</li>

<li>Teller, Paul, 1976, &#8220;Conditionalization, Observation, and
Change of Preference&#8221;, in W. Harper and C.A. Hooker
(eds.), <em>Foundations of Probability Theory, Statistical Inference,
and Statistical Theories of Science</em>, Dordrecht: D. Reidel.</li>

<li>Van Fraassen, Bas C., 1983, &#8220;Calibration: A Frequency
Justification for Personal Probability&#8221;, in R.S. Cohen and
L. Laudan (eds.), <em>Physics, Philosophy, and Psychoanalysis: Essays
in Honor of Adolf Grunbaum</em>, Dordrecht: Reidel.</li>

<li>&#8211;&#8211;&#8211;, 1984, &#8220;Belief and the
Will&#8221;, <em>Journal of Philosophy</em>, 81: 235&#8211;256.</li>

<li>&#8211;&#8211;&#8211;, 1995, &#8220;Belief and the Problem of
Ulysses and the Sirens&#8221;, <em>Philosophical Studies</em>, 77:
7&#8211;37.</li>

<li>Williamson, Jon, 1999, &#8220;Countable Additivity and Subjective
Probability&#8221;, <em>British Journal for the Philosophy of
Science</em>, 50: 401&#8211;416.</li>

<li>&#8211;&#8211;&#8211;, 2007, &#8220;Motivating Objective
Bayesianism: From Empirical Constraints to Objective
Probabilities,&#8221; in W. E. Harper and G. R. Wheeler
(eds.), <em>Probability and Inference: Essays in Honour of Henry
E. Kyburg, Jr.</em>, Amsterdam: Elsevier.</li>

<li>Zynda, Lyle, 1995, &#8220;Old Evidence and New
Theories&#8221;, <em>Philosophical Studies</em>, 77: 67&#8211;95.</li>

</ul>

</div>

<div id="academic-tools">

<h2><a name="Aca">Academic Tools</a></h2>

<blockquote>
<table>
<tr>
<td valign="top"><img src="https://plato.stanford.edu/symbols/sepman-icon.jpg" alt="sep man icon"></td>
<td><a href="https://plato.stanford.edu/cgi-bin/encyclopedia/archinfo.cgi?entry=epistemology-bayesian" target="other">How to cite this entry</a>.</td>
</tr>

<tr>
<td valign="top"><img src="https://plato.stanford.edu/symbols/sepman-icon.jpg" alt="sep man icon"></td>
<td><a href="https://leibniz.stanford.edu/friends/preview/epistemology-bayesian/" target="other">Preview the PDF version of this entry</a> at the
 <a href="https://leibniz.stanford.edu/friends/" target="other">Friends of the SEP Society</a>.</td>
</tr>

<tr>
<td valign="top"><img src="https://plato.stanford.edu/symbols/inpho.png" alt="inpho icon"></td>
<td><a href="https://www.inphoproject.org/entity?sep=epistemology-bayesian&amp;redirect=True" target="other">Look up this entry topic</a>
 at the <a href="https://www.inphoproject.org/" target="other">Internet Philosophy Ontology Project</a>
 (InPhO).</td>
</tr>

<tr>
<td valign="top"><img src="https://plato.stanford.edu/symbols/pp.gif" alt="phil papers icon"></td>
<td><a href="http://philpapers.org/sep/epistemology-bayesian/" target="other">Enhanced bibliography for this entry</a>
at <a href="http://philpapers.org/" target="other">PhilPapers</a>, with links to its database.</td>
</tr>

</table>
</blockquote>

</div>

<div id="other-internet-resources">

<h2><a name="Oth">Other Internet Resources</a></h2>

<ul>

<li>Charles, J., Hocker, A., Lacker, H., Le Diberder, F.R., T'Jampens,
S., 2006, 
 &#8220;<a href="http://arxiv.org/pdf/hep-ph/0607246v1.pdf" target="other">Bayesian Statistics at Work: the Troublesome Extraction of the CKM Phase alpha</a>,&#8221;
  preprint at ArXiv.org.</li>

</ul>

</div>

<div id="related-entries">

<h2><a name="Rel">Related Entries</a></h2>

<p>

 <a href="https://plato.stanford.edu/entries/bayes-theorem/">Bayes&#8217; Theorem</a> |
 <a href="https://plato.stanford.edu/entries/logic-inductive/">logic: inductive</a> |
 <a href="https://plato.stanford.edu/entries/probability-interpret/">probability, interpretations of</a>

</p>

</div>

<div id="acknowledgments">

<h3>Acknowledgments</h3>

 <p>

In the preparation of this article, I have benefited from comments
from Marc Lange, Stephen Glaister, Laurence BonJour, and James
Joyce.</p>

</div>

</div><!-- #aueditable --><!--DO NOT MODIFY THIS LINE AND BELOW-->

<!-- END ARTICLE HTML -->

</div> 